environment:
  python_requirements_txt: requirements.txt
inputs:
  chat_history:
    type: list
    is_chat_history: true
    default: []
  question:
    type: string
    is_chat_input: true
    default: Tell me about your tents.
outputs:
  answer:
    type: string
    reference: ${rag.output}
    is_chat_output: true
  context:
    type: string
    reference: ${get_context.output}
    is_chat_output: true
  intent:
    type: string
    reference: ${summarize_user_intent_llm.output}
nodes:
- name: summarize_user_intent_llm
  type: llm
  source:
    type: code
    path: summarize_user_intent_llm.jinja2
  inputs:
    deployment_name: ${config.output.AZURE_CHATGPT_DEPLOYMENT}
    temperature: 0.7
    top_p: 1
    max_tokens: 256
    presence_penalty: 0
    frequency_penalty: 0
    chat_history: ${inputs.chat_history}
    query: ${inputs.question}
  connection: connection-azure-open-ai
  api: chat
  aggregation: false
- name: get_context
  type: python
  source:
    type: code
    path: get_context.py
  inputs:
    question: ${summarize_user_intent_llm.output}
    azure_open_ai_connection: connection-azure-open-ai
    embedding_deployment: ${config.output.AZURE_OPENAI_EMBEDDING_DEPLOYMENT}
    azure_search_connection: connection-cognitive-search
    index_name: rag-promptflow-index
  aggregation: false
- name: rag_system_prompt
  type: prompt
  source:
    type: code
    path: rag_system_prompt.jinja2
  inputs:
    context_list: ${get_context.output}
  aggregation: false
- name: rag
  type: python
  source:
    type: code
    path: rag.py
  inputs:
    system_prompt: ${rag_system_prompt.output}
    chat_history: ${inputs.chat_history}
    query: ${inputs.question}
    azure_open_ai_connection: connection-azure-open-ai
    deployment_name: ${config.output.AZURE_CHATGPT_DEPLOYMENT}
  aggregation: false
- name: config
  type: python
  source:
    type: code
    path: config.py
  inputs: {}
